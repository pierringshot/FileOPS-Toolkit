# ğŸ§  FileOps Toolkit â€“ Unified File Deduplication & Transfer Framework

**AI/DevOps Training Specification Document**

---

## ğŸ¯ Ãœmumi MÉ™qsÉ™d

YÃ¼ksÉ™k performanslÄ±, paralel, tÉ™hlÃ¼kÉ™siz vÉ™ idarÉ™ olunan fayl deduplikasiya vÉ™ transfer sistemi yaratmaq. MÉ™qsÉ™d:

- `/mnt/f` vÉ™ `/mnt/d` kimi mÉ™nbÉ™lÉ™rdÉ™ki `.iso` (vÉ™ digÉ™r seÃ§ilmiÅŸ uzantÄ±lÄ±) fayllarÄ± tapmaq,
- onlarÄ± `/mnt/e/ISO/` kimi mÉ™rkÉ™zi qovluÄŸa toplamaq,
- eyni adlÄ± vÉ™ ya eyni mÉ™zmunlu fayllar Ã¼Ã§Ã¼n Ã¶lÃ§Ã¼ â†’ tarix â†’ hash mÃ¼qayisÉ™si aparmaq,
- É™n uyÄŸun faylÄ± saxlamaq (digÉ™rini kÃ¶Ã§Ã¼rmÉ™mÉ™k vÉ™ ya backup-dir-É™ saxlamaq),
- É™mÉ™liyyatlarÄ±n hamÄ±sÄ±nÄ± rÉ™ngli Ã§Ä±xÄ±ÅŸ, CSV/JSON log, retry/recovery vÉ™ interaktiv konfiqurasiya menyusu ilÉ™ mÃ¼ÅŸayiÉ™t etmÉ™k.

---

## ğŸ§± Arxitektura vÉ™ Modul DizaynÄ±

| Modul | TÉ™svir |
| --- | --- |
| **1ï¸âƒ£ Discovery Engine** | `find` vÉ™ ya `fdfind` vasitÉ™silÉ™ mÉ™nbÉ™ qovluqlarÄ± skan edir, `.iso` vÉ™ `.ISO` fayllarÄ± tapÄ±r, null-delimited fayl siyahÄ±sÄ± Ã§Ä±xarÄ±r. |
| **2ï¸âƒ£ Metadata Scanner** | HÉ™r fayl Ã¼Ã§Ã¼n `stat` mÉ™lumatlarÄ±nÄ± vÉ™ istÉ™yÉ™ gÃ¶rÉ™ `xxh128`, `sha1`, `md5` vÉ™ s. hash dÉ™yÉ™rlÉ™rini Ã§Ä±xarÄ±r. |
| **3ï¸âƒ£ Deduplication Core** | Eyni ad vÉ™ ya eyni hash-É™ malik fayllarÄ± aÅŸkar edir vÉ™ konfiqurasiya siyasÉ™tinÉ™ É™sasÉ™n qÉ™rar verir (saxla, É™vÉ™z et, backup et, atla). |
| **4ï¸âƒ£ Transfer Engine** | `rsync` vÉ™ ya `rclone` É™sasÄ±nda paralel kÃ¶Ã§Ã¼rmÉ™. Local vÉ™ ya SSH Ã¼zÉ™rindÉ™n. Retry vÉ™ partial resume dÉ™stÉ™yi var. |
| **5ï¸âƒ£ Verification Module** | KÃ¶Ã§Ã¼rÃ¼lÉ™n fayllarÄ±n Ã¶lÃ§Ã¼ vÉ™ hash uyÄŸunluÄŸunu yoxlayÄ±r. |
| **6ï¸âƒ£ Logging & Analytics** | BÃ¼tÃ¼n É™mÉ™liyyatlar CSV, JSON vÉ™ human-readable loglara yazÄ±lÄ±r. Realtime progress bar vÉ™ statistikalar gÃ¶stÉ™rilir. |
| **7ï¸âƒ£ Interactive Console (CLI/TUI)** | Ä°stifadÉ™Ã§i interfeysi â€” parametrlÉ™ri dÉ™yiÅŸmÉ™k, É™mÉ™liyyatlara nÉ™zarÉ™t etmÉ™k, loglarÄ± izlÉ™mÉ™k. |
| **8ï¸âƒ£ Supervisor / Scheduler** | Worker-lÉ™ri idarÉ™ edir, Ã§Ã¶kmÉ™ vÉ™ retry-lÉ™ri nÉ™zarÉ™tdÉ™ saxlayÄ±r, uzunmÃ¼ddÉ™tli É™mÉ™liyyatlarÄ± davam etdirir. |

---

## ğŸ§© Æsas MÉ™ntiq (Deduplication Logic)

| AddÄ±m | Qayda | ÆmÉ™liyyat |
| --- | --- | --- |
| 1ï¸âƒ£ | Fayl adÄ± eynidirsÉ™ | MÃ¼qayisÉ™yÉ™ keÃ§ |
| 2ï¸âƒ£ | Ã–lÃ§Ã¼lÉ™r fÉ™rqlidirsÉ™ | BÃ¶yÃ¼k olan qalÄ±r |
| 3ï¸âƒ£ | Ã–lÃ§Ã¼lÉ™r eynidirsÉ™ | Modifikasiya tarixi mÃ¼qayisÉ™ olunur |
| 4ï¸âƒ£ | TarixlÉ™r eynidirsÉ™ | Hash mÃ¼qayisÉ™si (`xxh128`, `sha1`, `md5`) aparÄ±lÄ±r |
| 5ï¸âƒ£ | Hash eynidirsÉ™ | Duplicate â€” skip vÉ™ log |
| 6ï¸âƒ£ | Hash fÉ™rqlidirsÉ™ | `keep_both_with_suffix` vÉ™ ya `prefer_newer` siyasÉ™ti ilÉ™ saxlanÄ±lÄ±r |

NÉ™ticÉ™ hÉ™r zaman log vÉ™ CSV faylÄ±nda qeyd olunur.

---

## âš™ï¸ Konfiqurasiya NÃ¼munÉ™si (`config.yml`)

```yaml
sources:
  - /mnt/f
  - /mnt/d
destination: /mnt/e/ISO
extensions: ['iso', 'ISO']
parallel_workers: 12
checksum_algo: xxh128
deduplication_policy: prefer_newer
transfer_tool: rsync
rsync_args:
  - "-aHAX"
  - "--sparse"
  - "--preallocate"
  - "--partial"
  - "--info=progress2,stats4"
logging:
  dir: /var/log/fileops
  csv_file: operations-$(date +%F_%T).csv
  json_file: summary.json
dry_run: false
verify_after_transfer: true
backup_duplicates_to: /mnt/e/Backup
```

---

## ğŸ’» Interaktiv Menyu (TUI/CLI)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       FILEOPS TOOLKIT MENU       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 1) Start full scan & collect
 2) Dry-run mode (simulation)
 3) Edit configuration (YAML)
 4) Show current progress
 5) Review dedup decisions
 6) View CSV/JSON logs
 7) Manage retry queue
 8) SSH source management
 9) Stop / Resume operations
 0) Exit
```

---

## ğŸ“Š CSV Log Format

| SÃ¼tun | Ä°zah |
| --- | --- |
| run_id | Cari iÅŸ sessiyasÄ± ID-si |
| timestamp | UTC vaxtÄ± |
| worker | Ä°cra edÉ™n iÅŸÃ§i |
| src_path | MÉ™nbÉ™ fayl yolu |
| dst_path | HÉ™dÉ™f fayl yolu |
| size_bytes | Fayl Ã¶lÃ§Ã¼sÃ¼ |
| mtime_unix | Modifikasiya vaxtÄ± |
| hash | FaylÄ±n hash dÉ™yÉ™ri |
| decision | copied / skipped / replaced / duplicate |
| reason | size_diff / newer / hash_match / error |
| duration_ms | Ä°ÅŸin mÃ¼ddÉ™ti |
| rsync_exit | Rsync Ã§Ä±xÄ±ÅŸ kodu |
| error_msg | SÉ™hv baÅŸ verdikdÉ™ mesaj |

---

## ğŸ§¾ Pre-checks (Ä°cra Ã¶ncÉ™si yoxlamalar)

- `find`, `rsync`, `xargs` vÉ™ `xxh*` komandalarÄ±nÄ±n mÃ¶vcudluÄŸu
- MÉ™nbÉ™ vÉ™ hÉ™dÉ™f qovluqlarÄ±n mÃ¶vcudluÄŸu vÉ™ icazÉ™lÉ™ri
- DiskdÉ™ minimum boÅŸ yer (`min_free_bytes`)
- Rsync versiyasÄ± vÉ™ flag dÉ™stÉ™klÉ™ri (`--preallocate`, `--mkpath`)
- SSH baÄŸlantÄ±sÄ± (É™gÉ™r uzaq host gÃ¶stÉ™rilibsÉ™)
- Uzaq hostlar Ã¼Ã§Ã¼n `remote_staging_dir` yazÄ±la bilmÉ™lidir vÉ™ parol istifadÉ™ olunursa `sshpass` mÃ¶vcudluÄŸu tÉ™sdiqlÉ™nmÉ™lidir

---

## âš¡ Paralel Ä°ÅŸ Modeli (Bash versiya Ã¼Ã§Ã¼n nÃ¼munÉ™)

```bash
find /mnt/f /mnt/d -type f -iname '*.iso' -print0 |
  xargs -0 -n1 -P 12 /usr/local/bin/iso-worker.sh
```

**iso-worker.sh** faylÄ± isÉ™:

- fayl Ã¼Ã§Ã¼n `stat` toplayÄ±r,
- hÉ™dÉ™fi yoxlayÄ±r,
- mÃ¼qayisÉ™ aparÄ±r,
- `rsync` Ã§aÄŸÄ±rÄ±r,
- nÉ™ticÉ™ni CSV-yÉ™ É™lavÉ™ edir,
- konsola rÉ™ngli nÉ™ticÉ™ verir (`green=success`, `yellow=duplicate`, `red=error`).

---

## ğŸ“ˆ ÆmÉ™liyyat AxÄ±nÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Discovery  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metadata Scanâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dedup Engine â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transfer Coreâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV / Logger â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§° TÃ¶vsiyÉ™ Olunan Texnologiyalar

| SÉ™viyyÉ™ | DillÉ™r / Kitabxanalar | XÃ¼susiyyÉ™tlÉ™r |
| --- | --- | --- |
| ğŸŸ¢ Bash Edition | find, xargs, rsync, awk, xxh128sum | Minimalist, portativ |
| ğŸŸ£ Python Edition | rich, click, xxhash, concurrent.futures, paramiko | Interaktiv CLI, TUI, CSV, Ã§oxlu worker |
| ğŸŸ¡ Go Edition | cobra, go-xxhash, rsync wrapper | Enterprise sÉ™viyyÉ™li, statik binary, Ã§ox sÃ¼rÉ™tli |

---

## ğŸ”’ TÉ™hlÃ¼kÉ™sizlik vÉ™ Retry MexanizmlÉ™ri

- `--remove-source-files` yalnÄ±z uÄŸurlu transferdÉ™n sonra aktivlÉ™ÅŸir
- HÉ™r É™mÉ™liyyat Ã¼Ã§Ã¼n maksimum 3 retry (exponential backoff ilÉ™)
- IO sÉ™hvlÉ™ri `errors.log` faylÄ±nda qeyd olunur
- `dry-run` rejimi default aktiv olur (istifadÉ™Ã§i tÉ™sdiq etmÉ™sÉ™, heÃ§ nÉ™ dÉ™yiÅŸmir)
- Backup-dir bÃ¼tÃ¼n overwrite É™mÉ™liyyatlarÄ±nda istifadÉ™ olunur

---

## ğŸ§  AI Model Ã¼Ã§Ã¼n TÉ™lim TÉ™limatÄ± (Training Prompt)

> â€œDevelop an AI or automation system that can execute the **FileOps Toolkit** pipeline described above â€” capable of discovering, deduplicating, transferring, logging, and verifying files across local and remote paths using parallel workers, rsync, and interactive configuration. The system should ensure safety, high performance, recoverability, and full traceability in all operations.â€

---

## ğŸ§­ Repository Description (GitHub Ã¼Ã§Ã¼n qÄ±sa versiya)

---

## ğŸ” ÆlavÉ™ FunksionallÄ±q (v0.2)

- **Pattern Discovery** â€” `patterns` vÉ™ `pattern_mode` (glob/regex) vasitÉ™silÉ™ istÉ™nilÉ™n fayl maskalarÄ±nÄ± dÉ™stÉ™klÉ™yir, `pattern_case_sensitive` parametrilÉ™ idarÉ™ olunur.
- **ÆmÉ™liyyat ModlarÄ±** â€” `operation_mode: flatten` deduplikasiya olunmuÅŸ toplama; `operation_mode: mirror` isÉ™ qovluq strukturunu olduÄŸu kimi saxlayÄ±r (`mirror_prefix_with_root` seÃ§imi ilÉ™).
- **Duplikat StrategiyasÄ±** â€” `duplicates_policy` (`skip`, `archive`, `delete`) vÉ™ `duplicates_archive_dir` ilÉ™ eyni mÉ™zmunlu fayllar Ã¼Ã§Ã¼n idarÉ™ olunan davranÄ±ÅŸ.
- **Verbosity ProfilÉ™ri** â€” CLI Ã§Ä±xÄ±ÅŸÄ±nÄ± `minimal`, `standard`, `maximal` rejimlÉ™rinÉ™ bÃ¶lÃ¼r, menyuda da dinamik gÃ¶stÉ™rilir.
- **Interaktiv Konfiq Editoru** â€” menyuda yeni alt-menyu mÉ™nbÉ™/destination/pattern/mode/dry-run kimi parametrlÉ™ri redaktÉ™ edir vÉ™ Ã§atÄ±ÅŸmayan qovluqlarÄ± avtomatik yaradÄ±r.
- **Remote Staging & SSH Sync** â€” `remote_sources`, `remote_rsync_args`, `remote_staging_dir` parametrlÉ™ri ilÉ™ `rsync` Ã¼zÉ™rindÉ™n uzaq hostlarÄ± lokal keÅŸÉ™ gÉ™tirir, menyuda idarÉ™ olunur, `sshpass` dÉ™stÉ™yi ilÉ™ parol/SSH aÃ§arÄ± ilÉ™ iÅŸlÉ™yir.
- **ASCII Banner** â€” CLI aÃ§Ä±lÄ±ÅŸÄ±nda FileOps Toolkit Ã¼Ã§Ã¼n xÃ¼susi ASCII art + mÃ¼É™llif imzasÄ± (PierringShot Electronics / github.com/pierringshot).


> ğŸ”§ **FileOps Toolkit** â€” Modular, parallel, and intelligent file deduplication & transfer system.
> Finds, compares, merges, and verifies large files (ISO, media, archives) with rsync integration, real-time logs, and an interactive console.

---

## ğŸ“œ License

MIT License Â© 2025 â€” FileOps Toolkit Authors

---

## ğŸ§‘â€ğŸ’» Contributing

Pull requests vÉ™ plugin tÉ™kliflÉ™ri aÃ§Ä±qdÄ±r. Ä°stifadÉ™Ã§i modullarÄ±, transfer alÉ™tlÉ™ri vÉ™ dedup strategiyalarÄ± Ã¼Ã§Ã¼n API-lÉ™r planlaÅŸdÄ±rÄ±lÄ±b.

---

Ä°ndi sÉ™n sadÉ™cÉ™ demÉ™lisÉ™n:
- â€œBash prototipi Ã¼Ã§Ã¼n repo skeleton yaratâ€  
  yaxud  
- â€œPython CLI versiyasÄ± Ã¼Ã§Ã¼n tam struktur yarat (src/, config/, logs/, setup.py, README.md, LICENSE vÉ™ s.)â€

HansÄ± versiyanÄ± istÉ™yirsÉ™n ki tam iÅŸlÉ™k GitHub reposu kimi formalaÅŸdÄ±raq?
# FileOps Toolkit â€“ Python CLI Edition

Modular, parallel, and intelligent file deduplication & transfer system described in the training brief.  
The current repository provides a Python-first skeleton with Click/Rich based CLI, pluggable modules, and configuration-driven policies ready to be extended into a production-grade toolkit.

## Repository layout

```
FileOPS-Toolkit/
  src/fileops_toolkit/
    console/        # CLI entrypoints (Rich tables, Click commands, future TUI)
    discovery/      # File discovery walkers (fd/find wrappers welcome)
    metadata/       # Metadata + checksum collection (md5/sha1/xxh128)
    deduplication/  # Policy engine for deciding copy/skip/replace
    transfer/       # rsync-backed transfer utilities with retry hooks
    verification/   # Post-transfer verification helpers
    logging/        # CSV/JSON logging helpers and analytics stubs
    supervisor/     # Worker orchestration + retry scaffolding
    config_loader.py
  config/config.yml # Example configuration mirrors the spec
  logs/             # Runtime logs (ignored by git)
  requirements.txt
  setup.py
  LICENSE
  AGENTS.md         # Full AI/DevOps training specification
```

Every module is intentionally lightweight but documented so new contributors can grow it toward the target behaviour (parallel workers, retries, remote transfer, etc.).

## Architecture overview

| Module | Purpose |
| --- | --- |
| **Discovery Engine** | Scans configured sources (`find`, `fd`, or native walker) and emits candidate files as pathlib paths. |
| **Metadata Scanner** | Collects stat info + checksums (`md5`, `sha1`, `xxh128`) for downstream dedup decisions. |
| **Deduplication Core** | Implements policies such as `prefer_newer` or `keep_both_with_suffix`, comparing name â†’ size â†’ mtime â†’ hash. |
| **Transfer Engine** | Wraps `rsync` (extensible to `rclone`/SSH) with directory pre-creation, retry hooks, and resumable flags. |
| **Verification Module** | Confirms size/hash parity after transfer before marking success. |
| **Logging & Analytics** | Writes CSV/JSON/human logs, intended to back progress dashboards and audit trails. |
| **Interactive Console** | Click/Rich CLI providing scan/show-config today, with placeholders for full menu-driven control. |
| **Supervisor / Scheduler** | Thread-based worker orchestration scaffold; extend with `concurrent.futures`, retry queues, and resume logic. |

## Features roadmap

- Parallel discovery & transfer workers with resumable retries.
- Policy-driven deduplication decisions (size â†’ mtime â†’ hash).
- Rich-powered CLI with colour themes, progress indicators, and verbose toggles.
- Dry-run mode by default; confirmation required before destructive work.
- Backup directory support for overwrite scenarios.
- Future TUI for interactive monitoring and configuration edits.

## CLI usage

The CLI currently exposes `scan`, `show-config`, and `menu`, complete with progress bars, verbose detail toggles, and a colour-off switch. Extend `src/fileops_toolkit/console/main.py` with additional commands for dedup, transfer, verification, etc.

```bash
python -m fileops_toolkit.console.main --help
python -m fileops_toolkit.console.main scan --config config/config.yml
python -m fileops_toolkit.console.main scan --config config/config.yml --verbose
python -m fileops_toolkit.console.main scan --no-color
python -m fileops_toolkit.console.main show-config
python -m fileops_toolkit.console.main menu
```

Running directly from the repository root? Export `PYTHONPATH=src` (or install the package in editable mode) so Python picks up the local modules rather than any previously installed wheel.

Future menu (as per spec) is sketched below for reference:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       FILEOPS TOOLKIT MENU       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 1) Start full scan & collect
 2) Dry-run mode (simulation)
 3) Edit configuration (YAML)
 4) Show current progress
 5) Review dedup decisions
 6) View CSV/JSON logs
 7) Manage retry queue
 8) SSH source management
 9) Stop / Resume operations
 0) Exit
```

## Configuration

`config/config.yml` mirrors the sample in the specification. Adjust paths, policies, or checksum algorithms to suit your environment.

```yaml
sources:
  - /mnt/f
  - /mnt/d
destination: /mnt/e/ISO
extensions: ['iso', 'ISO']
parallel_workers: 12
checksum_algo: xxh128
deduplication_policy: prefer_newer
transfer_tool: rsync
rsync_args:
  - "-aHAX"
  - "--sparse"
  - "--preallocate"
  - "--partial"
  - "--info=progress2,stats4"
logging:
  dir: ./logs
  csv_file: operations-$(date +%F_%T).csv
  json_file: summary.json
dry_run: true
verify_after_transfer: true
backup_duplicates_to: /mnt/e/Backup
```

## Logging format

The logging helper sets up CSV columns ready for full telemetry:

`run_id`, `timestamp`, `worker`, `src_path`, `dst_path`, `size_bytes`, `mtime_unix`, `hash`, `decision`, `reason`, `duration_ms`, `rsync_exit`, `error_msg`.

JSON logs capture serialised `DedupResult` objects for downstream dashboards or analytics.

## Pre-checks

- Ensure `find`, `rsync`, `xargs`, and configured hash utilities are installed.
- Confirm source/destination directories exist with sufficient permissions and free space.
- Validate your `rsync` supports `--preallocate`, `--partial`, `--info=progress2`.
- Test SSH connectivity when remote hosts appear in configuration.

## Example parallel runner (bash sketch)

```bash
find /mnt/f /mnt/d -type f -iname '*.iso' -print0 \
  | xargs -0 -n1 -P 12 /usr/local/bin/iso-worker.sh
```

`iso-worker.sh` should gather metadata, consult dedup policy, invoke `rsync`, append to CSV, and emit color-coded console results (`green=success`, `yellow=duplicate`, `red=error`).

## Workflow snapshot

```
Discovery â†’ Metadata Scan â†’ Dedup Engine â†’ Transfer Core â†’ CSV / Logger â†’ Verification
```

## Getting started

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python -m fileops_toolkit.console.main scan
```

## License

MIT License Â© 2025 â€” FileOps Toolkit Authors
